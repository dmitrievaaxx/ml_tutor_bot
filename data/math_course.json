{
  "course": "Math",
  "lessons": [
    {
      "lesson_number": 1,
      "title": "Векторы и операции",
      "content": "Определение: Вектор — это упорядоченный набор чисел (компонентов), который можно представить как точку в n-мерном пространстве. Вектор записывается как v = [v₁, v₂, ..., vₙ], где каждый элемент vᵢ является координатой в соответствующем измерении.\n\nОсновные операции с векторами:\n\n1. Сложение векторов\na + b = [a1+b1, a2+b2, ..., an+bn]\nПример:\na = [3, 4], b = [1, 2]\na + b = [3+1, 4+2] = [4, 6]\n\n2. Умножение на скаляр\nk * a = [k*a1, k*a2, ..., k*an]\nПример:\nk = 2, a = [3, 4]\nk * a = [2*3, 2*4] = [6, 8]\n\n3. Скалярное произведение\na · b = a1*b1 + a2*b2 + ... + an*bn\nПример:\na = [3, 4], b = [1, 2]\na · b = 3*1 + 4*2 = 3 + 8 = 11\n\n4. Норма вектора\na = sqrt(a1^2 + a2^2 + ... + an^2)\nПример:\na = [3, 4]\na = sqrt(3^2 + 4^2) = sqrt(9 + 16) = sqrt(25) = 5\n\nПрименение в ML: Векторы используются для представления признаков объектов (feature vectors), хранения весов нейронных сетей и описания состояний систем. Скалярное произведение применяется для вычисления сходства между объектами."
    },
    {
      "lesson_number": 2,
      "title": "Матрицы и основные операции",
      "content": "Определение: Матрица — это прямоугольная таблица чисел, организованная в m строк и n столбцов. Матрица размера m×n записывается как A = [aᵢⱼ], где aᵢⱼ — элемент, расположенный в i-й строке и j-м столбце. Матрицы являются фундаментальными объектами линейной алгебры.\n\nОсновные операции с матрицами:\n1. Умножение матриц\nC = A × B, где c[i][j] = sum(A[i][k] * B[k][j])\nПример:\nДано: A = [[1, 2], [3, 4]], B = [[5, 6], [7, 8]]\nC[0][0] = 1*5 + 2*7 = 5 + 14 = 19\nC[0][1] = 1*6 + 2*8 = 6 + 16 = 22\nC[1][0] = 3*5 + 4*7 = 15 + 28 = 43\nC[1][1] = 3*6 + 4*8 = 18 + 32 = 50\nРезультат: C = [[19, 22], [43, 50]]\n\n2. Транспонирование\nA^T[i][j] = A[j][i]\nПример:\nДано: A = [[1, 2, 3], [4, 5, 6]]\nA^T = [[1, 4], [2, 5], [3, 6]]\n\n3. Детерминант (для квадратных матриц 2×2)\ndet(A) = a*d - b*c\nПример:\nДано: A = [[3, 1], [2, 4]]\ndet(A) = 3*4 - 1*2 = 12 - 2 = 10\n\nПрименение в ML: Матрицы используются для представления наборов данных (строки = объекты, столбцы = признаки), хранения весов нейронных сетей и выполнения линейных преобразований в алгоритмах машинного обучения."
    },
    {
      "lesson_number": 3,
      "title": "Собственные значения и векторы",
      "content": "Определение: Собственные значения и векторы — это фундаментальные понятия линейной алгебры.\nДля квадратной матрицы A собственный вектор v и собственное значение λ удовлетворяют уравнению\nAv = λv (Av - λv = 0, (A - λ)*v = 0), где v ≠ 0.\n\nОсновные свойства:\n1) Вектор v называется собственным вектором матрицы A, если Av = λv для некоторого скаляра λ\n2) Скаляр λ называется собственным значением, если существует ненулевой вектор v такой, что Av = λv\n3) Характеристическое уравнение (в общем виде) для матрицы 2×2: det([[a - λ, b], [c, d - λ]]) = (a - λ)(d - λ) - bc = 0\n\nПример:\nПусть A = [[3, 1], [0, 2]]\n\n1) Составим характеристическое уравнение: det(A - λI) = (3 - λ)(2 - λ)\n2) Решаем (3 - λ)(2 - λ) = 0 → λ₁ = 3, λ₂ = 2\n3) λ = 3: A - 3I = [[0, 1], [0, -1]] -> решаем (A - 3I)v = 0 → v₁ = (1, 0)\n4) λ = 2: A - 2I = [[1, 1], [0, 0]] -> решаем (A - 2I)v = 0 → v₂ = (1, -1)\n\nОтвет:\nλ₁ = 3, v₁ = (1, 0)\nλ₂ = 2, v₂ = (1, -1)\n\nПрименение в ML:\nСобственные векторы используются в PCA для нахождения главных компонент данных, в анализе стабильности систем и сжатии информации. Собственные значения показывают, насколько «важно» каждое направление в данных."
    },
    {
      "lesson_number": 4,
      "title": "Ортогональность и проекции",
      "content": "Определение: Ортогональность — это свойство векторов быть перпендикулярными. Два вектора a и b ортогональны, если их скалярное произведение равно нулю: a · b = 0.\n\n1. Ортогональные векторы\nДва вектора ортогональны, если угол между ними равен 90°, то есть a · b = 0.\nПример:\na = [1, 0], b = [0, 1]\na · b = 1×0 + 0×1 = 0 → векторы перпендикулярны.\n\n2. Ортонормированные векторы\nВекторы, которые ортогональны и имеют длину 1.\nПример: [1, 0] и [0, 1] образуют ортонормированный базис в 2D-пространстве.\nОртонормированные базисы удобны, так как проекции и расстояния в них считаются просто.\n\n3. Ортогональные матрицы\nМатрица Q называется ортогональной, если выполняется QᵀQ = I. Это значит, что её столбцы (и строки) образуют ортонормированный базис.\nОртогональные матрицы сохраняют длину и углы между векторами, то есть описывают вращения и отражения в пространстве.\nПример:\nQ = [[0, -1], [1, 0]] — это матрица поворота на 90°, и действительно QᵀQ = I.\n\n4. Проекция вектора\nПроекция вектора a на вектор b показывает, насколько a направлен вдоль b.\nНапример, проекция [3, 4] на ось X равна [3, 0].\n(Можно думать, что мы \"бросаем тень\" вектора на направление b.)\n\nПрименение в ML:\nОртогональность используется в PCA для нахождения независимых направлений в данных, в регуляризации нейронных сетей (orthogonal initialization), в обработке сигналов при разложении по ортогональным базисам (например, в Фурье-преобразовании)."
    },
    {
      "lesson_number": 5,
      "title": "SVD и PCA",
      "content": "Определение:\nSVD (Singular Value Decomposition) — это разложение любой матрицы A на три матрицы: A = U Σ Vᵀ, где U и V — ортонормированные матрицы, а Σ — диагональная матрица сингулярных значений.\nPCA (Principal Component Analysis) — метод снижения размерности данных, который находит направления наибольшей изменчивости (главные компоненты) и проецирует данные на них.\n\nСмысл методов и наглядные примеры\n1) SVD: выделяет основные структуры матрицы; малые сингулярные значения можно отбросить.\nПример: Для матрицы изображения SVD выделяет основные паттерны и позволяет отбросить малозначимые компоненты, тем самым сжимая изображение без сильной потери качества.\n2) PCA: находит направления, вдоль которых данные меняются сильнее всего. Для этого вычисляется ковариационная матрица данных, находятся её собственные векторы и собственные значения. Главные компоненты — это эти собственные векторы, отсортированные по убыванию собственных значений.\nПример: для роста и веса людей первая главная компонента показывает, что рост и вес растут вместе\n\nПрименение в ML:\nSVD — в рекомендательных системах, сжатии данных и факторизации матриц\nPCA — для визуализации многомерных данных, удаления шума и уменьшения числа признаков перед обучением моделей"
    },
    {
      "lesson_number": 6,
      "title": "Производные и частные производные",
      "content": "Определение: Производная функции показывает скорость изменения функции в данной точке. Частная производная показывает скорость изменения функции по одной переменной при фиксированных остальных.\n\nОсновные понятия:\n1. Производная функции\nПроизводная f'(x) показывает, насколько быстро изменяется функция f(x) в точке x.\nПример:\nДля функции f(x) = x² производная f'(x) = 2x. В точке x = 3 производная равна 6.\n\n2. Частная производная\nЧастная производная ∂f/∂xᵢ показывает изменение функции по переменной xᵢ при фиксированных остальных.\nПример:\nДля функции f(x,y) = x² + 2xy частная производная по x: ∂f/∂x = 2x + 2y.\n\n3. Основные правила дифференцирования\n- Производная константы: d/dx(c) = 0\n- Производная степени: d/dx(xⁿ) = nxⁿ⁻¹\n- Производная экспоненты: d/dx(eˣ) = eˣ\n- Производная логарифма: d/dx(ln(x)) = 1/x\nПример:\nДля функции f(x) = x³ + eˣ производная f'(x) = 3x² + eˣ.\n\nПрименение в ML: Производные используются в градиентном спуске для нахождения направления убывания функции потерь, в оптимизации параметров нейронных сетей и анализе функций активации."
    },
    {
      "lesson_number": 7,
      "title": "Градиенты и цепное правило",
      "content": "Определение: Градиент — это вектор частных производных функции по всем переменным. Цепное правило позволяет вычислять производные сложных функций через производные их компонентов.\n\nОсновные понятия:\n1. Градиент функции\nГрадиент ∇f показывает направление наибольшего роста функции и его величину.\nПример:\nДля функции f(x,y) = x² + y² градиент ∇f = [2x, 2y]. В точке (1,2) градиент равен [2, 4].\n\n2. Цепное правило\nДля композиции функций f(g(x)) производная равна произведению производных: d/dx[f(g(x))] = f'(g(x)) × g'(x).\nПример:\nДля функции f(x) = (x² + 1)³ производная f'(x) = 3(x² + 1)² × 2x = 6x(x² + 1)².\n\n3. Обратное распространение ошибки\nВ нейронных сетях градиенты вычисляются от выходного слоя к входному через цепное правило.\nПример:\nДля слоя с активацией σ(Wx + b) градиент по весам W вычисляется как произведение градиента следующего слоя на производную активации и входные данные.\n\nПрименение в ML: Градиенты используются для обучения нейронных сетей через обратное распространение ошибки, оптимизации параметров и анализа чувствительности моделей к изменениям входных данных."
    },
    {
      "lesson_number": 8,
      "title": "Градиентный спуск (GD, SGD)",
      "content": "Градиентный спуск (Gradient Descent) — это метод оптимизации, который находит минимум функции, двигаясь в направлении, противоположном градиенту.\nЕсли градиент указывает направление наибольшего роста функции, то движение в противоположную сторону ведёт к уменьшению значения функции.\n\nФормула градиентного спуска:\nПусть мы минимизируем функцию потерь L(θ), где θ — это вектор параметров модели.\n\nОбновление параметров на шаге t записывается как:\nθ(t+1) = θ(t) - α ∇θ L(θ(t))\n\nгде:\n- θ(t) — параметры на текущем шаге,\n- α — скорость обучения (learning rate),\n- ∇θ L(θ(t)) — градиент функции потерь по параметрам.\n\nВарианты градиентного спуска:\n\n1. Batch Gradient Descent (Полный градиентный спуск)\nГрадиент вычисляется по всему датасету:\n∇θ L(θ) = (1/n) Σᵢ ∇θ Lᵢ(θ)\n- Точный, но медленный на больших данных.\n- Требует прогонки по всему датасету перед каждым шагом обновления.\n\n2. Stochastic Gradient Descent (SGD)\nИспользует один случайный пример для оценки градиента:\n∇θ L(θ) = ∇θ Lᵢ(θ)\nОбновление:\nθ(t+1) = θ(t) - α ∇θ Lᵢ(θ(t))\n- Быстрее, так как не требует обработки всего набора данных.\n- Обновления шумные, из-за чего значения функции могут колебаться, но это помогает избежать локальных минимумов.\n- Хорошо подходит для онлайн-обучения и больших датасетов.\n\n3. Mini-Batch Gradient Descent\nКомпромисс между двумя подходами.\nГрадиент считается по небольшой подвыборке (batch) размера m:\n∇θ L(θ) = (1/m) Σᵢ∈batch ∇θ Lᵢ(θ)\n- Баланс между скоростью и стабильностью.\n- Является стандартным методом при обучении нейросетей.\n\nПрименение:\n- Градиентный спуск — основа обучения нейронных сетей.\n- SGD и mini-batch SGD позволяют эффективно обучать модели на больших данных, обеспечивая быстрые и частые обновления параметров.\n- На основе SGD построены продвинутые методы (Momentum, RMSProp, Adam и др.), которые ускоряют сходимость и стабилизируют обучение."
    },
    {
      "lesson_number": 9,
      "title": "Adam и другие оптимизаторы",
      "content": "Современные методы оптимизации развивают идею градиентного спуска, добавляя инерцию, адаптивные скорости обучения и комбинированные стратегии.\nК числу наиболее популярных относятся Momentum, RMSprop и Adam.\n\n1. Momentum\nДобавляет «инерцию» к градиентному спуску, что помогает преодолевать локальные минимумы и уменьшает колебания\nФормулы:\nv_t = γv_{t-1} + α∇L(θ_t)\nθ_{t+1} = θ_t - v_t\nгде:\n- γ ∈ [0,1) — коэффициент затухания импульса (обычно 0.9),\n- α — скорость обучения,\n- v_t — накопленный импульс (momentum).\nОсобенности:\n- Ускоряет движение вдоль направлений с постоянным градиентом.\n- Помогает избежать «застревания» в локальных минимумах.\n- Делает траекторию обучения более гладкой.\n\n2. RMSprop\nАдаптивно регулирует скорость обучения для каждого параметра, чтобы уменьшить влияние больших градиентов.\nФормулы:\nv_t = γv_{t-1} + (1 - γ)g_t²\nθ_{t+1} = θ_t - α × g_t / (√(v_t) + ε)\nгде:\n- γ — коэффициент сглаживания (обычно 0.9),\n- g_t — градиент на шаге t,\n- ε — малое число для стабильности (обычно 10⁻⁸).\nОсобенности:\n- Уменьшает шаг для часто обновляемых параметров.\n- Эффективен при обучении рекуррентных нейронных сетей (RNN).\n- Поддерживает стабильную сходимость даже при нестабильных данных.\n\n3. Adam (Adaptive Moment Estimation)\nAdam сочетает идеи Momentum и RMSprop, обеспечивая адаптивное изменение скорости обучения и ускоряя сходимость.\nФормулы обновления Adam:\nПусть g_t = ∇θ L(θ_t) — градиент функции потерь на шаге t.\n\n1. Вычисление экспоненциальных средних:\nm_t = β₁ m_{t-1} + (1 - β₁) g_t\nv_t = β₂ v_{t-1} + (1 - β₂) g_t²\n2. Коррекция смещения:\nm̂_t = m_t / (1 - β₁ᵗ)\nv̂_t = v_t / (1 - β₂ᵗ)\n3. Обновление параметров:\nθ_{t+1} = θ_t - α × m̂_t / (√(v̂_t) + ε)\nгде:\n- α — скорость обучения (обычно 0.001),\n- β₁, β₂ — коэффициенты экспоненциального сглаживания (по умолчанию 0.9 и 0.999),\n- ε — небольшое число для предотвращения деления на ноль (например, 10⁻⁸).\nОсобенности:\n- Быстрая сходимость даже при шумных градиентах.\n- Адаптивный шаг для каждого параметра.\n- Наиболее популярный оптимизатор в глубоком обучении.\n\nПрименение:\n- Momentum ускоряет обучение на сложных ландшафтах функции потерь.\n- RMSprop эффективен для RNN и задач с нестационарными данными.\n- Adam используется практически во всех современных нейросетевых архитектурах (CNN, RNN, Transformer) благодаря своей устойчивости и скорости сходимости"
    },
    {
      "lesson_number": 10,
      "title": "Выпуклые и невыпуклые функции",
      "content": "Определение: Выпуклая функция — это функция, график которой лежит ниже любой хорды, соединяющей две точки на графике. Невыпуклые функции могут иметь множество локальных минимумов.\n\nОсновные типы функций:\n1. Выпуклые функции\nФункция f выпукла, если для любых x₁, x₂ и λ ∈ [0,1]: f(λx₁ + (1-λ)x₂) ≤ λf(x₁) + (1-λ)f(x₂)\nПример:\nКвадратичная функция f(x) = x² выпукла, так как любая хорда лежит выше параболы.\n\n2. Свойства выпуклых функций\nЛюбой локальный минимум является глобальным минимумом, градиентный спуск гарантированно находит минимум.\nПример:\nДля функции f(x) = x² минимум в точке x = 0 является единственным и глобальным.\n\n3. Невыпуклые функции\nМогут иметь множество локальных минимумов, градиентный спуск может застрять в локальном минимуме.\nПример:\nФункция f(x) = x⁴ - 4x² имеет локальные минимумы в точках x = ±√2 и локальный максимум в x = 0.\n\nПрименение в ML: Выпуклые функции используются в линейной регрессии, SVM и логистической регрессии для гарантированного нахождения глобального оптимума. Невыпуклые функции встречаются в нейронных сетях и требуют специальных методов оптимизации."
    },
    {
      "lesson_number": 11,
      "title": "Функции потерь (MSE, Cross-Entropy)",
      "content": "Функция потерь (Loss Function) — это мера того, насколько плохо модель предсказывает данные. Она показывает разницу между предсказанными и реальными значениями.\nЦель обучения — минимизировать значение функции потерь.\n\n1. MSE (Mean Squared Error)\nСреднеквадратичная ошибка. Часто используется в задачах регрессии.\nФормула:\nL = (1/n) Σᵢ (yᵢ - ŷᵢ)²\nгде:\n- yᵢ — истинное значение,\n- ŷᵢ — предсказание модели,\n- n — количество примеров.\nПример:\nДля предсказаний [1, 2, 3] и реальных значений [1.1, 1.9, 3.2]:\nMSE = (0.1² + 0.1² + 0.2²) / 3 = 0.02\nОсобенности:\n- Сильно штрафует большие ошибки (выбросы).\n- Может быть чувствительна к шумным данным.\n\n2. MAE (Mean Absolute Error)\nСредняя абсолютная ошибка. Также используется в регрессии.\nФормула:\nL = (1/n) Σᵢ |yᵢ - ŷᵢ|\nПример:\nДля тех же данных:\nMAE = (|0.1| + |0.1| + |0.2|) / 3 = 0.133\n\nОсобенности:\n- Менее чувствительна к выбросам, чем MSE\n\n3. Cross-Entropy Loss\nИспользуется в задачах классификации, особенно при вероятностных выходах модели.\nФормула (для бинарной классификации):\nL = -[y log(ŷ) + (1 - y) log(1 - ŷ)]\nили в общем виде:\nL = -Σᵢ yᵢ log(ŷᵢ)\nПример:\nДля вероятностей [0.8, 0.2] и меток [1, 0]:\nLoss = -(1×log(0.8) + 0×log(0.2)) = -log(0.8) ≈ 0.22\n\nОсобенности:\n- Сильно штрафует уверенные, но неверные предсказания.\n- Используется в логистической регрессии и нейронных сетях для классификации.\n\nПрименение в ML:\n- MSE — классическая функция потерь для линейной и нейронной регрессии.\n- MAE — предпочтительна при наличии выбросов, так как устойчивее к ним.\n- Cross-Entropy — основной выбор для задач классификации."
    },
    {
      "lesson_number": 12,
      "title": "Регуляризация (L1, L2)",
      "content": "Определение: Регуляризация — это техника, которая добавляет штраф к функции потерь для предотвращения переобучения модели. Она помогает модели лучше обобщаться на новых данных.\n\nОсновные типы регуляризации:\n1. L2 регуляризация (Ridge)\nДобавляет штраф за сумму квадратов весов: L(θ) = MSE(θ) + λΣθᵢ²\nПример:\nДля весов [2, -1, 3] и λ = 0.1: штраф = 0.1 × (2² + (-1)² + 3²) = 0.1 × 14 = 1.4\n\n2. L1 регуляризация (Lasso)\nДобавляет штраф за сумму абсолютных значений весов: L(θ) = MSE(θ) + λΣ|θᵢ|\nПример:\nДля весов [2, -1, 3] и λ = 0.1: штраф = 0.1 × (|2| + |-1| + |3|) = 0.1 × 6 = 0.6\n\n3. Elastic Net\nКомбинирует L1 и L2 регуляризацию: L(θ) = MSE(θ) + λ₁Σ|θᵢ| + λ₂Σθᵢ²\nПример:\nДля весов [2, -1, 3], λ₁ = 0.05, λ₂ = 0.05: штраф = 0.05 × 6 + 0.05 × 14 = 0.3 + 0.7 = 1.0\n\nПрименение в ML: L2 регуляризация используется в Ridge регрессии для стабильности. L1 регуляризация применяется в Lasso для отбора признаков. Elastic Net сочетает преимущества обеих методов."
    },
    {
      "lesson_number": 13,
      "title": "Градиенты в матричной форме",
      "content": "Градиенты в матричной форме — это способ вычисления производных функций от векторов и матриц. Это основа для оптимизации в машинном обучении.\n\nОсновные правила матричного дифференцирования:\n1. Градиент линейной функции\nДля функции f(x) = aᵀx градиент равен: ∇f(x) = a\nПример:\nДля a = [2, 3] и x = [x₁, x₂]: f(x) = 2x₁ + 3x₂, ∇f(x) = [2, 3]\n\n2. Градиент квадратичной формы\nДля функции f(x) = xᵀAx градиент равен: ∇f(x) = (A + Aᵀ)x\nПример:\nДля A = [[1, 2], [0, 1]] и x = [1, 1]: ∇f(x) = (A + Aᵀ)x = [[2, 2], [2, 2]] × [1, 1] = [4, 4]\n\n3. Градиент нормы\nДля функции f(x) = ||x||² градиент равен: ∇f(x) = 2x\nПример:\nДля x = [3, 4]: f(x) = 3² + 4² = 25, ∇f(x) = 2 × [3, 4] = [6, 8]\n\nПрименение в ML: Градиенты в матричной форме используются в градиентном спуске для обновления весов w = w - α∇L(w), в обратном распространении ошибки для вычисления градиентов в нейронных сетях и в оптимизации для поиска минимума функции потерь."
    },
    {
      "lesson_number": 14,
      "title": "Случайные величины и распределения",
      "content": "Случайная величина — это функция, которая каждому исходу случайного эксперимента ставит в соответствие число.\nОна описывает неопределённость в данных и является основой для статистического анализа и вероятностных моделей в машинном обучении.\n\nТипы случайных величин:\n1. Дискретные — принимают конечное или счётное число значений (например, Бернулли, Бином, Пуассон).\n2. Непрерывные — могут принимать любые значения на интервале (например, Нормальное, Равномерное, Экспоненциальное).\n\n1. Нормальное распределение N(μ, σ²)\nНепрерывное распределение, описывающее естественные флуктуации случайных величин.\nХарактеризуется параметрами:\n- μ — математическое ожидание (среднее),\n- σ² — дисперсия (меры разброса).\nФормула плотности:\nf(x) = (1 / √(2πσ²)) × e^(-(x - μ)² / (2σ²))\nПример:\nДля N(0, 1) (стандартное нормальное распределение):\n- Вероятность попадания в интервал [-1, 1] ≈ 68%.\n- В интервал [-2, 2] ≈ 95%.\n- В интервал [-3, 3] ≈ 99.7%.\n\nОсобенности:\n- Симметрично относительно среднего.\n- Используется для описания ошибок измерений, шума и распределений признаков.\n\n2. Распределение Бернулли B(p)\nДискретное распределение, описывающее случайный эксперимент с двумя исходами: \"успех\" (1) и \"неудача\" (0).\nВероятности:\nP(X = 1) = p\nP(X = 0) = 1 - p\nПример:\nДля честной монеты с p = 0.5:\nP(орёл) = 0.5,  P(решка) = 0.5.\nХарактеристики:\n- Математическое ожидание: E[X] = p\n- Дисперсия: D[X] = p(1 - p)\nПрименяется для моделирования бинарных событий (например, классификация 0/1).\n\n3. Равномерное распределение U(a, b)\nНепрерывное распределение, при котором все значения на интервале [a, b] равновероятны.\nФормула плотности:\nf(x) = 1 / (b - a), если x ∈ [a, b],\nf(x) = 0, иначе.\nПример:\nДля U(0, 1):\n- Все значения от 0 до 1 равновероятны.\n- Плотность вероятности f(x) = 1.\nХарактеристики:\n- Математическое ожидание: E[X] = (a + b)/2\n- Дисперсия: D[X] = (b - a)² / 12\nИспользуется при инициализации весов в нейросетях и генерации случайных параметров.\n\nПрименение в машинном обучении:\n- Генеративные модели (VAE, GAN) используют случайные величины для моделирования распределений данных.\n- Байесовские методы применяют распределения для описания неопределённости в параметрах модели.\n- Стохастические алгоритмы оптимизации (например, SGD) используют случайные величины для выбора подвыборок данных.\n- Анализ ошибок и оценка вероятностей опираются на предположения о распределениях случайных величин."
    },
    {
      "lesson_number": 15,
      "title": "Матожидание, дисперсия, ковариация",
      "content": "Математическое ожидание показывает среднее значение случайной величины, дисперсия измеряет разброс значений относительно среднего, а ковариация — степень линейной зависимости между двумя случайными величинами.\n\n1. Математическое ожидание (E[X])\nПоказывает, к какому значению в среднем стремится случайная величина.\nФормула:\n- Для дискретной случайной величины:\n  E[X] = Σ xᵢ × P(X = xᵢ)\n- Для непрерывной:\n  E[X] = ∫ x × f(x) dx\nПример:\nДля броска игрального кубика (все исходы равновероятны):\nE[X] = (1 + 2 + 3 + 4 + 5 + 6) / 6 = 3.5\nСвойства:\n- E[aX + b] = aE[X] + b\n- Математическое ожидание линейно.\n\n2. Дисперсия (Var(X))\nХарактеризует разброс значений случайной величины вокруг её среднего.\nФормула:\nVar(X) = E[(X - E[X])²] = E[X²] - (E[X])²\nПример:\nДля игрального кубика:\nE[X²] = (1² + 2² + 3² + 4² + 5² + 6²) / 6 = 91/6 ≈ 15.17\nVar(X) = 15.17 - 3.5² = 2.92\nСвойства:\n- Var(aX + b) = a²Var(X)\n- Var(X) ≥ 0, при постоянной X дисперсия равна 0.\nИнтерпретация:\nДисперсия показывает, насколько значения случайной величины отклоняются от среднего.\nЧасто используют среднеквадратичное отклонение (σ):\nσ = √Var(X)\n\n3. Ковариация (Cov(X, Y))\nИзмеряет направление и силу линейной зависимости между двумя случайными величинами.\nФормула:\nCov(X, Y) = E[(X - E[X]) (Y - E[Y])]\nПример:\n- Для независимых X и Y: Cov(X, Y) = 0.\n- Если X и Y растут вместе: Cov(X, Y) > 0.\n- Если одно растёт, а другое уменьшается: Cov(X, Y) < 0.\nСвойства:\n- Cov(X, X) = Var(X)\n- Cov(aX, bY) = ab Cov(X, Y)\nИнтерпретация:\nКовариация показывает, как изменения одной величины связаны с изменениями другой.\nОднако она зависит от масштаба — поэтому часто используют коэффициент корреляции: ρ(X, Y) = Cov(X, Y) / (σₓσᵧ)\n\n\nПрименение в машинном обучении:\n- Математическое ожидание используется для центрирования данных (удаления среднего).\n- Дисперсия — для нормализации признаков и оценки стабильности распределений.\n- Ковариация — для анализа взаимосвязей между признаками и построения ковариационных матриц (например, в PCA)."
    },
    {
      "lesson_number": 16,
      "title": "Байесовская теорема",
      "content": "Байесовская теорема — это фундаментальная формула теории вероятностей, которая описывает, как пересчитывать (обновлять) вероятность события при получении новой информации.\nОна связывает априорные знания о событии с наблюдаемыми данными.\n\n1. Формула Байеса\nФормула:\nP(A | B) = [ P(B | A) × P(A) ] / P(B)\n\nгде:\n- P(A | B) — апостериорная вероятность (вероятность A после наблюдения B),\n- P(B | A) — правдоподобие (насколько вероятно наблюдение B, если A истинно),\n- P(A) — априорная вероятность (предварительная оценка вероятности A до наблюдений),\n- P(B) — нормализующий множитель (вероятность наблюдения B при всех возможных A).\n\nПример:\nПусть 1% людей болеют заболеванием:\nP(A) = 0.01\nТест точен на 95% (верно определяет болезнь):\nP(B | A) = 0.95\nНо даёт ложноположительный результат в 5% случаев:\nP(B | ¬A) = 0.05\n\nТогда:\nP(B) = P(B | A)P(A) + P(B | ¬A)P(¬A)\n      = 0.95×0.01 + 0.05×0.99 = 0.059\n\nАпостериорная вероятность:\nP(A | B) = (0.95 × 0.01) / 0.059 ≈ 0.161\n\n2. Наивный байесовский классификатор\nИспользует упрощённое предположение о независимости признаков при заданном классе.\n\nФормула:\nP(Класс | Признаки) ∝ P(Класс) × ∏ P(Признакᵢ | Класс)\n\nПояснение:\nВероятность принадлежности к классу вычисляется как произведение априорной вероятности класса\nна вероятности появления каждого признака при условии этого класса.\n\nПример:\nДля задачи фильтрации спама:\nP(спам | слово₁, слово₂) ∝ P(спам) × P(слово₁ | спам) × P(слово₂ | спам)\n\nЗатем сравнивают P(спам | признаки) и P(не спам | признаки) — и выбирают класс с большей вероятностью.\n\nОсобенности:\n- Прост в реализации и требует мало данных.\n- Хорошо работает при большом количестве независимых признаков.\n- Эффективен для текстовой классификации, анализа отзывов и фильтрации спама.\n\nПрименение в машинном обучении:\n- Наивный байесовский классификатор — один из базовых и быстрых методов классификации.\n- Байесовские нейронные сети используют теорему Байеса для учёта неопределённости в весах.\n- Байесовская оптимизация применяет вероятностную модель для подбора гиперпараметров.\n- Инференция в вероятностных графовых моделях (например, Hidden Markov Models) основана на байесовских вычислениях."
    },
    {
      "lesson_number": 17,
      "title": "Maximum Likelihood Estimation (MLE)",
      "content": "Метод максимального правдоподобия — это способ оценки параметров статистической модели, при котором выбираются такие значения параметров,\nкоторые делают наблюдаемые данные наиболее вероятными.\n\nПусть у нас есть модель с параметром θ и выборка наблюдений X = {x₁, x₂, …, xₙ}.\nТогда функция правдоподобия определяется как:\nL(θ) = P(X | θ) = ∏ P(xᵢ | θ)\n\nМетод максимального правдоподобия выбирает параметр θ̂, при котором вероятность наблюдения данных максимальна:\nθ̂ = argmax_θ L(θ)\nНа практике обычно берут логарифм (логарифмическую функцию правдоподобия), чтобы упростить вычисления:\nℓ(θ) = log L(θ) = Σ log P(xᵢ | θ)\n\n\nПрименение в машинном обучении:\n- Оценка параметров вероятностных моделей (напр., Гауссовы смеси, логистическая регрессия, наивный Байес).\n- Обучение моделей с использованием максимизации правдоподобия эквивалентно минимизации функции потерь на основе отрицательного логарифма:\n  Loss = −ℓ(θ)"
    },
    {
      "lesson_number": 18,
      "title": "Энтропия и дивергенции",
      "content": "1. Энтропия (Entropy)\nЭнтропия измеряет среднюю неопределенность случайной величины X с распределением P:\nH(P) = − Σ P(x) log P(x)\nОсобенности:\n- Чем выше неопределенность, тем больше энтропия.\n- Для равномерного распределения энтропия максимальна.\n- Используется для построения информативных моделей и оценки информации.\nПример:\nДля монеты с P(орёл) = 0.5, P(решка) = 0.5:\nH = −(0.5 log 0.5 + 0.5 log 0.5) = 1 бит\n\n2. Кросс-энтропия (Cross-Entropy)\nКросс-энтропия измеряет, насколько одно распределение Q (предсказанное моделью) отличается от истинного распределения P:\nH(P, Q) = − Σ P(x) log Q(x)\n\nОсобенности:\n- Используется как функция потерь в классификации (Cross-Entropy Loss).\n- Минимизация кросс-энтропии эквивалентна максимизации правдоподобия.\nПример:\nЕсли P = [1, 0], Q = [0.8, 0.2]:\nH(P, Q) = −(1*log0.8 + 0*log0.2) ≈ 0.22\n\n3. KL-дивергенция (Kullback-Leibler divergence)\nKL-дивергенция измеряет «расстояние» или различие между распределениями P и Q:\nD_KL(P || Q) = Σ P(x) log (P(x)/Q(x)) = H(P, Q) − H(P)\nОсобенности:\n- D_KL(P || Q) ≥ 0, D_KL(P || Q) = 0 только если P = Q\n- Используется для регуляризации вероятностных моделей и в вариационных автоэнкодерах (VAE)\n- Несимметричная мера различия между распределениями\n\n\nПрименение в машинном обучении:\n- Энтропия: измерение неопределенности предсказаний.\n- Кросс-энтропия: функция потерь для классификационных моделей (логистическая регрессия, нейросети).\n- KL-дивергенция: оценка различий между предсказанным и истинным распределением, регуляризация и вариационные методы."
    }
  ]
}
